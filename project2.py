# -*- coding: utf-8 -*-
"""project2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18GAzlgv0pRa6j__nYw-NyADP4EtJoMZK
"""

!pip install keras
!pip install numpy
!pip install pandas
!pip install tensorflow
!pip install lime
!pip install json

!pip install Pillow

import shutil
import random
import numpy as np
import json
import zipfile
import os
import pandas as pd
import PIL
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from tensorflow.keras.models import Sequential
import os
from keras.models import Model
from keras.applications.vgg16 import VGG16, preprocess_input
from keras.layers import Dense, Flatten
import numpy as np
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import lime
from lime import lime_image
from PIL import Image

!wget "http://seppe.net/aa/assignment2/images.zip"
!7z x images.zip

from google.colab import drive
drive.mount('/content/gdrive')

! rm images.zip

import os
images_path = '/content/images'
dataset_path = '/content/gdrive/My Drive/dataset.json'

"""Extract the price categories and store them in a library where they are linked to images. (We will later need this as a dataframe)"""

with open(dataset_path, "r") as f:
    data = json.load(f)
price_categories = {}
image_ids = []
for item in data:
    # Check if 'price_category' key is present in the 'item' dictionary
    if 'price_category' in item and item['price_category'] is not None:
        # Extract the price category
        price_category = item['price_category']['label']
        # Extract the image IDs from the "full_images" list and map them to their price category
        for img in item["more_details"]["full_images"]:
            image_id = img["image_id"]
            image_ids.append(image_id)
            price_categories[image_id] = price_category

"""Now I have a list of image id's and a library of price categories.
The file names of the images are just the id with .jpg behind it.
I want to create the training, validation and test set.
For this I need to make a pandas data frame with two columns, with the image file names and one with the categories.

First, we shuffle the image id's and then split them up in training, validation and test set lists of image id's.(The training, validation, test sizes are 70%, 20% and 10%. We could, however **change these values 0.07, 0.02, 0.01 to lower values if we want to use less of the data**.)
"""

random.shuffle(image_ids)  # shuffle image id's

train_size = 0.07
val_size = 0.02
test_size = 0.01

train_image_ids = image_ids[:int(len(image_ids) * train_size)]
val_image_ids = image_ids[int(len(image_ids) * train_size):int(len(image_ids) * (train_size + val_size))]
test_image_ids = image_ids[int(len(image_ids) * (train_size + val_size)):int(len(image_ids) * (train_size + val_size + test_size))]

"""Now we create lists of the filenames of these images."""

train_filenames = [f"{image_id}.jpg" for image_id in train_image_ids]
val_filenames = [f"{image_id}.jpg" for image_id in val_image_ids]
test_filenames = [f"{image_id}.jpg" for image_id in test_image_ids]

"""Now, we create a pandas dataframe with two columns: "filename" and "price_category"."""

train_df = pd.DataFrame(
    {"id": train_filenames, "label": [price_categories[image_id] for image_id in train_image_ids]})
val_df = pd.DataFrame(
    {"id": val_filenames, "label": [price_categories[image_id] for image_id in val_image_ids]})
test_df = pd.DataFrame(
    {"id": test_filenames, "label": [price_categories[image_id] for image_id in test_image_ids]})

"""We set the paths for the training, validation, and test data directories and create the directories.

We set the paths for the training, validation, and test data directories and create the directories.
"""

# delete the directories if they are there already
if os.path.exists('/content/images/train'):
    shutil.rmtree('/content/images/train')
else:
    print(f"The folder '{'/content/images/train'}' does not exist yet.")

if os.path.exists('/content/images/val'):
    shutil.rmtree('/content/images/val')
else:
    print(f"The folder '{'/content/images/val'}' does not exist yet.")

if os.path.exists('/content/images/test'):
    shutil.rmtree('/content/images/test')
else:
    print(f"The folder '{'/content/images/test'}' does not exist yet.")

# Set the paths for the training, validation, and test data directories
train_data_dir = os.path.join(images_path, "train")
val_data_dir = os.path.join(images_path, "val")
test_data_dir = os.path.join(images_path, "test")

# Create the directories if they don't exist already
!mkdir -p "{train_data_dir}"
!mkdir -p "{val_data_dir}"
!mkdir -p "{test_data_dir}"

"""We move the image files to the appropriate directories."""

from PIL import Image

def is_image_corrupted(image_path):
    try:
        Image.open(image_path)
        return False
    except (IOError, SyntaxError):
        return True

for filename in train_filenames:
    src_path = os.path.join(images_path, filename)
    dst_path = os.path.join(train_data_dir, filename)
    is_corrupted = is_image_corrupted(src_path)
    if is_corrupted:
        print(f"corrupted image: {filename}")
    else:
        shutil.move(src_path, dst_path)

for filename in val_filenames:
    src_path = os.path.join(images_path, filename)
    dst_path = os.path.join(val_data_dir, filename)
    is_corrupted = is_image_corrupted(src_path)
    if is_corrupted:
        print(f"corrupted image: {filename}")
    else:
        shutil.move(src_path, dst_path) 

for filename in test_filenames:
    src_path = os.path.join(images_path, filename)
    dst_path = os.path.join(test_data_dir, filename)
    is_corrupted = is_image_corrupted(src_path)
    if is_corrupted:
        print(f"corrupted image: {filename}")
    else:
        shutil.move(src_path, dst_path)

"""Now we want to preprocess the data and then generate it.

We first define the image dimensions and the batch size. **(Change this, see what works best)**
"""

img_width, img_height = 224, 224
batch_size = 32

"""We use ImageDataGenerator for preprocessing including rotation augmentation."""

train_datagen = ImageDataGenerator(rescale=1. / 255, rotation_range=20, fill_mode='nearest')
val_datagen = ImageDataGenerator(rescale=1. / 255)
test_datagen = ImageDataGenerator(rescale=1. / 255)

"""We generate the training, validation, and testing datasets."""

train_generator = train_datagen.flow_from_dataframe(
        dataframe = train_df,
        directory='/content/images/train',
        target_size=(224,224),
        x_col="id",
        y_col="label",
        seed=42,
        shuffle=True,
        class_mode="categorical",
        batch_size=32)

validation_generator = val_datagen.flow_from_dataframe(
        dataframe = val_df,
        directory='/content/images/val',
        target_size=(224,224),
        x_col="id",
        y_col="label",
        seed=42,
        shuffle=True,
        class_mode="categorical",
        batch_size=32)

test_generator = test_datagen.flow_from_dataframe(
        dataframe = test_df,
        directory='/content/images/test',
        target_size=(224,224),
        x_col="id",
        y_col="label",
        seed=42,
        shuffle=False,
        class_mode="categorical",
        batch_size=32)

"""Now we can finally build our Neural Network. We created one by hand at first, and then used a pretrained model (VGG16) to compare the results.

Define the CNN structure.
"""

model = Sequential()
model.add(Conv2D(32, (3, 3), input_shape=(img_width, img_height, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dense(64, activation='relu'))
model.add(Dense(4, activation='softmax'))

"""Compile the model."""

model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

"""Train the model.(**Number of epochs can be changed**)"""

history = model.fit_generator(train_generator, steps_per_epoch=train_generator.samples // batch_size, epochs=5, 
                              validation_data=validation_generator, validation_steps=validation_generator.samples // batch_size)

"""Evaluate the model."""

test_loss, test_acc = model.evaluate_generator(test_generator, steps=test_generator.samples // batch_size)
print('Test accuracy:', test_acc)
print('Test loss:', test_loss)

"""Interpreter LIME

"""

import matplotlib.pyplot as plt
from skimage.segmentation import mark_boundaries
!pip install scikit-image
from matplotlib import cm

# Modify the colormap
colormap = cm.get_cmap('viridis')
explainer = lime_image.LimeImageExplainer()


def predict_wrapper(images):
    # This function is a wrapper around the model's prediction function
    # It takes in a batch of images (N, 224, 224, 3) and returns the predicted probabilities (N, 5)
    # Modify this function according to your specific model's prediction function
    return model.predict(images)


# Get an example image from the validation set
example_image_path = os.path.join(val_data_dir, val_filenames[100])
example_image = Image.open(example_image_path).resize((224, 224))

# Explain the model's prediction for the example image
explanation = explainer.explain_instance(np.array(example_image), predict_wrapper, top_labels=5)

# Show the LIME visualization for the explanation
temp_1, mask_1 = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=False)
temp_2, mask_2 = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=10, hide_rest=False)

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,15))
ax1.imshow(mark_boundaries(temp_1, mask_1))
ax2.imshow(mark_boundaries(temp_2, mask_2))
ax1.axis('off')
ax2.axis('off')

"""Now, we do the same thing but with the pretrained model VGG16.

We first preprocess and generate.
"""

# preprocessing according to VGG16
batch_size = 256
train_datagen = ImageDataGenerator(rescale=1. / 255, rotation_range=90,
                                     brightness_range=[0.1, 0.7],
                                     width_shift_range=0.5,
                                     height_shift_range=0.5,
                                     horizontal_flip=True,
                                     vertical_flip=True,
                                     validation_split=0.15,
                                     preprocessing_function=preprocess_input)
val_datagen = ImageDataGenerator(rescale=1. / 255,preprocessing_function=preprocess_input)
test_datagen = ImageDataGenerator(rescale=1. / 255,preprocessing_function=preprocess_input)

# Generate the training, validation, and testing datasets (I followed the instructions on https://www.learndatasci.com/tutorials/hands-on-transfer-learning-keras/)
train_generator = train_datagen.flow_from_dataframe(
        dataframe = train_df,
        directory='/content/images/train',
        target_size=(224,224),
        x_col="id",
        y_col="label",
        seed=42,
        shuffle=True,
        class_mode="categorical",
        batch_size=256)

validation_generator = val_datagen.flow_from_dataframe(
        dataframe = val_df,
        directory='/content/images/val',
        target_size=(224,224),
        x_col="id",
        y_col="label",
        seed=42,
        shuffle=True,
        class_mode="categorical",
        batch_size=256)

test_generator = test_datagen.flow_from_dataframe(
        dataframe = test_df,
        directory='/content/images/test',
        target_size=(224,224),
        x_col="id",
        y_col="label",
        seed=42,
        shuffle=False,
        class_mode="categorical",
        batch_size=256)

"""Load without the top layer input_shape(img_width, img_height, 3) (the 3 is for the colors rbg)."""

vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
for layer in vgg_model.layers:
    layer.trainable = False
    # This is to make sure we don't train these layers

"""We add a new output layer with 4 categories. Then we create the new model with the pretrained layers and our new output layer."""

x = Flatten()(vgg_model.output)
output_layer = Dense(4, activation='softmax')(x)

model_VGG = Model(inputs=vgg_model.input, outputs=output_layer)

"""Compile the model."""

model_VGG.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

"""Train the model. (**Number of epochs can be changed**)"""

history = model_VGG.fit_generator(train_generator, steps_per_epoch=train_generator.samples // batch_size, epochs=1,
                              validation_data=validation_generator, validation_steps=validation_generator.samples // batch_size)

"""Evaluate the model.

"""

test_loss, test_acc = model_VGG.evaluate_generator(test_generator, steps=test_generator.samples // batch_size)
print('Test accuracy:', test_acc)
print('Test loss:', test_loss)

"""LIME interpreter"""

import matplotlib.pyplot as plt
from skimage.segmentation import mark_boundaries
!pip install scikit-image
from matplotlib import cm

# Modify the colormap
colormap = cm.get_cmap('viridis')
explainer = lime_image.LimeImageExplainer()


def predict_wrapper(images):
    # This function is a wrapper around the model's prediction function
    # It takes in a batch of images (N, 224, 224, 3) and returns the predicted probabilities (N, 5)
    # Modify this function according to your specific model's prediction function
    return model.predict(images)


# Get an example image from the validation set
example_image_path = os.path.join(val_data_dir, val_filenames[2])
example_image = Image.open(example_image_path).resize((224, 224))

# Explain the model's prediction for the example image
explanation = explainer.explain_instance(np.array(example_image), predict_wrapper, top_labels=5)

# Show the LIME visualization for the explanation
temp_1, mask_1 = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=False)
temp_2, mask_2 = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=10, hide_rest=False)

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,15))
ax1.imshow(mark_boundaries(temp_1, mask_1))
ax2.imshow(mark_boundaries(temp_2, mask_2))
ax1.axis('off')
ax2.axis('off')

"""Now, for the ResNet50 pretrained model"""

from keras.applications import ResNet50

# Preprocessing
batch_size = 64
train_datagen = ImageDataGenerator(
    rescale=1. / 255,
    rotation_range=90,
    brightness_range=[0.1, 0.7],
    width_shift_range=0.5,
    height_shift_range=0.5,
    horizontal_flip=True,
    vertical_flip=True,
    validation_split=0.15,
    preprocessing_function=preprocess_input
)
val_datagen = ImageDataGenerator(rescale=1. / 255, preprocessing_function=preprocess_input)
test_datagen = ImageDataGenerator(rescale=1. / 255, preprocessing_function=preprocess_input)

# Generate the training, validation, and testing datasets
train_generator = train_datagen.flow_from_dataframe(
    dataframe=train_df,
    directory='/content/images/train',
    target_size=(224, 224),
    x_col="id",
    y_col="label",
    seed=42,
    shuffle=True,
    class_mode="categorical",
    batch_size=64
)

validation_generator = val_datagen.flow_from_dataframe(
    dataframe=val_df,
    directory='/content/images/val',
    target_size=(224, 224),
    x_col="id",
    y_col="label",
    seed=42,
    shuffle=True,
    class_mode="categorical",
    batch_size=64
)

test_generator = test_datagen.flow_from_dataframe(
    dataframe=test_df,
    directory='/content/images/test',
    target_size=(224, 224),
    x_col="id",
    y_col="label",
    seed=42,
    shuffle=False,
    class_mode="categorical",
    batch_size=64
)

# Load the ResNet50 model
resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Freeze the layers of the ResNet50 model
for layer in resnet_model.layers:
    layer.trainable = False

# Add your own classification layers on top of the ResNet50 model
x = Flatten()(resnet_model.output)
x = Dense(256, activation='relu')(x)
output_layer = Dense(4, activation='softmax')(x)

# Create the final model
model_resnet = Model(inputs=resnet_model.input, outputs=output_layer)

# Compile and train the model
model_resnet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
history_resnet = model_resnet.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // batch_size,
    epochs=5,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // batch_size
)

test_loss, test_acc = model_resnet.evaluate_generator(test_generator, steps=test_generator.samples // batch_size)
print('Test accuracy:', test_acc)
print('Test loss:', test_loss)

"""Now for EfficientNet"""

!pip install efficientnet
from keras.applications import EfficientNetB0


# Preprocessing
batch_size = 64
train_datagen = ImageDataGenerator(
    rescale=1. / 255,
    rotation_range=90,
    brightness_range=[0.1, 0.7],
    width_shift_range=0.5,
    height_shift_range=0.5,
    horizontal_flip=True,
    vertical_flip=True,
    validation_split=0.15,
    preprocessing_function=preprocess_input
)
val_datagen = ImageDataGenerator(rescale=1. / 255, preprocessing_function=preprocess_input)
test_datagen = ImageDataGenerator(rescale=1. / 255, preprocessing_function=preprocess_input)

# Generate the training, validation, and testing datasets
train_generator = train_datagen.flow_from_dataframe(
    dataframe=train_df,
    directory='/content/images/train',
    target_size=(224, 224),
    x_col="id",
    y_col="label",
    seed=42,
    shuffle=True,
    class_mode="categorical",
    batch_size=64
)

validation_generator = val_datagen.flow_from_dataframe(
    dataframe=val_df,
    directory='/content/images/val',
    target_size=(224, 224),
    x_col="id",
    y_col="label",
    seed=42,
    shuffle=True,
    class_mode="categorical",
    batch_size=64
)

test_generator = test_datagen.flow_from_dataframe(
    dataframe=test_df,
    directory='/content/images/test',
    target_size=(224, 224),
    x_col="id",
    y_col="label",
    seed=42,
    shuffle=False,
    class_mode="categorical",
    batch_size=64
)

# Load the EfficientNetB0 model
efficientnet_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# Freeze the layers of the EfficientNetB0 model
for layer in efficientnet_model.layers:
    layer.trainable = False

# Add your own classification layers on top of the EfficientNetB0 model
x = Flatten()(efficientnet_model.output)
x = Dense(256, activation='relu')(x)
output_layer = Dense(4, activation='softmax')(x)

# Create the final model
model_efficientnet = Model(inputs=efficientnet_model.input, outputs=output_layer)

# Compile and train the model
model_efficientnet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
history_efficientnet = model_efficientnet.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // batch_size,
    epochs=5,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // batch_size
)

test_loss, test_acc = model_efficientnet.evaluate_generator(test_generator, steps=test_generator.samples // batch_size)
print('Test accuracy:', test_acc)
print('Test loss:', test_loss)